# Logarithms

## Table of Contents

- [What is a Logarithm?](#what-is-a-logarithm)
- [Understanding Logarithms](#understanding-logarithms)
- [Mathematical Interpretation](#mathematical-interpretation)
- [Logarithmic Complexity](#logarithmic-complexity)
- [Why Does It Matter?](#why-does-it-matter)

---

## What is a Logarithm?

- In algorithm analysis, you may encounter:
  - `O(1)`, `O(n)`, `O(n^2)`
  - But sometimes you'll see logarithmic expressions too â€” like `O(log n)`

## Understanding Logarithms

- A logarithm is the **inverse of exponentiation**:

```

logâ‚‚(8) = 3 â‡’ 2Â³ = 8
logâ‚‚(value) = exponent â‡’ 2^exponent = value

```

- Rule of thumb:
- The logarithm of a number roughly measures **how many times you can divide it by 2 before getting â‰¤ 1**

### Example

If `n = 8`, we divide by 2 until we reach 1:

```

8 â†’ 4 â†’ 2 â†’ 1

```

This takes 3 steps â‡’ `logâ‚‚(8) = 3`

## Mathematical Interpretation

- In each step `k`:

```

When k = 0 â‡’ n / 2â° = n
When k = 1 â‡’ n / 2Â¹ = n/2
...

```

- Eventually:

```

n / 2^k = 1
â‡’ 2^k = n
â‡’ k = logâ‚‚(n)

```

## Logarithmic Complexity

- Logarithmic time complexity is **very efficient**.

```

O(log n) < O(n) < O(n log n) < O(nÂ²)

```

## Why Does It Matter?

- **Searching algorithms** like **binary search** run in `O(log n)` time.
- Some **efficient sorting algorithms** use `O(n log n)` time.
- **Recursion** can have logarithmic **space complexity** in divide-and-conquer algorithms.

---

> ğŸ” Understanding logarithms is essential when analyzing advanced algorithms â€” especially recursive or divide-and-conquer strategies.
